---
title: "Darwin Core mapping"
subtitle: "For: Checklist title"
author:
- author_1
- author_2
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    df_print: paged
---

# Setup 

```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Load libraries:

```{r}
library(tidyverse)      # To transform data
library(magrittr)       # To use %<>% pipes
library(janitor)        # To clean input data
library(readxl)         # To read Excel files
library(digest)         # To generate hashes
library(rgbif)          # To use GBIF services
```

# Read raw data

Create a data frame `raw_data` from the source data:

```{r}
raw_data <- read_excel(path = "../data/raw/checklist.xlsx") 
```

# Process raw data

## Rows and columns

Clean data somewhat:

```{r}
raw_data %<>%
  remove_empty("rows") %>%  # Remove empty rows
  clean_names()             # Have sensible (lowercase) column names
```

Add prefix `raw_` to all column names to avoid name clashes with Darwin Core terms:

```{r}
colnames(raw_data) <- paste0("raw_", colnames(raw_data))
```

## Preview data

```{r}
raw_data %>% head(n = 5)
```

## Scientific names

### Retrieve nomenclatural information

Use the [GBIF nameparser](https://www.gbif.org/tools/name-parser) to retrieve nomenclatural information for the scientific names in the checklist:

```{r}
parsed_names <- rgbif::parsenames(unique(raw_data$raw_scientific_name))
```

Show scientific names with nomenclatural issues, i.e. not of `type = SCIENTIFIC` or that could not be fully parsed. Note: these are not necessarily incorrect.

```{r}
parsed_names %>%
  select(scientificname, type, parsed, parsedpartially, rankmarker) %>%
  filter(!(type == "SCIENTIFIC" & parsed == "TRUE" & parsedpartially == "FALSE"))
```

Correct names and reparse:

```{r}
raw_data %<>% mutate(raw_scientific_name = recode(raw_scientific_name,
  "Asero√ô rubra" = "Asero rubra"
))

parsed_names <- rgbif::parsenames(unique(raw_data$raw_scientific_name))
parsed_names %>%
  select(scientificname, type, parsed, parsedpartially, rankmarker) %>%
  filter(!(type == "SCIENTIFIC" & parsed == "TRUE" & parsedpartially == "FALSE"))
```

### Add taxonRank information

The nameparser function also provides information about the rank of the taxon (in `rankmarker`). Here we join this information with our checklist. Cleaning these ranks will done in the Taxon Core mapping:

```{r}
raw_data %<>% left_join(
  select(parsed_names, scientificname, rankmarker),
  by = c("raw_scientific_name" = "scientificname")) %>%
  rename(raw_rankmarker = rankmarker)
```

### Generate taxonID

To link taxa with information in the extension(s), each taxon needs a unique and relatively stable taxonID. Here we create one in the form of `dataset_shortname:taxon:hash`, where `hash` is unique code based on scientific name and kingdom (that will remain the same as long as scientific name and kingdom remain the same):

```{r}
vdigest <- Vectorize(digest) # Vectorize digest function to work with vectors
raw_data %<>% mutate(raw_taxon_id = paste(
  "dataset_shortname", # Update with your dataset shortname
  "taxon",
  vdigest(paste(raw_scientific_name, raw_kingdom), algo = "md5"),
  sep = ":"
))
```

### Show summary

Show the number of taxa and distributions per kingdom and rank:

```{r}
raw_data %>%
  group_by(raw_kingdom, raw_rankmarker) %>%
  summarize(
    `# taxa` = n_distinct(raw_taxon_id),
    `# distributions` = n()
  )
```

# Create taxon core

Remove duplicated taxa and save as a new dataframe `taxon`:

```{r}
taxon <- raw_data %>% slice(which(duplicated(raw_data $ raw_taxon_id) == "FALSE")) 
```

## Term mapping
 
Map the data to [Darwin Core Taxon](http://rs.gbif.org/core/dwc_taxon_2015-04-24.xml).

The following terms are record-level terms (i.e. metadata):

### language

```{r}
taxon %<>% mutate(language = "this_is_a_language") 
```

### license

```{r}
taxon %<>% mutate(license = "this_is_the_license") 
```

### rightsHolder

```{r}
taxon %<>% mutate(rightsHolder = "this_is_the_rightsHOlder") 
```

### accessRights

```{r}
taxon %<>% mutate(accessRights = "these_are_the_accessRights") 
```

### datasetID

```{r}
taxon %<>% mutate(datasetID = "this_is_the_datasetID") 
```

### institutionCode

```{r}
taxon %<>% mutate(institutionCode = "this_is_the_institutionCode")
```

### datasetName

```{r}
taxon %<>% mutate(datasetName = "this_is_the_datasetName") 
```

The following terms are specific for the taxon information:

### taxonID

```{r}
taxon %<>% mutate(taxonID = raw_taxon_id) 
```

### scientificName

```{r}
taxon %<>% mutate(scientificName = raw_scientific_name) 
```

### kingdom

```{r}
taxon %<>% mutate(kingdom = raw_kingdom) 
```

### taxonRank

Overview of the content of `raw_rankmarker`:

```{r}
taxon %>% 
  select(raw_rankmarker) %>% 
  group_by_all() %>% 
  summarize(records =  n())
```

Recode rankmarker information to match GBIF vocabulary:

```{r}
taxon %<>% mutate(taxonRank = recode(raw_rankmarker,
  "agg." = "speciesAggregate",
  "infrasp." = "infraspecificname",
  "sp." = "species",
  "var." = "variety",
  .missing = ""))
```

### nomenclaturalCode

```{r}
taxon %<>% mutate(nomenclaturalCode = "this_is_the_nomenclaturalCode") 
```

## Post-processing

Remove the original columns:

```{r}
taxon %<>% select(-starts_with("raw_"))
```

Preview data:

```{r}
taxon %>% head()
```

Save to CSV:

```{r}
write.csv(taxon, file = "../data/processed/taxon.csv", na = "", row.names = FALSE, fileEncoding = "UTF-8")
```

# Create distribution extension

```{r}
distribution <- raw_data
```

## Term mapping 

Map the data to [Species Distribution](http://rs.gbif.org/extension/gbif/1.0/distribution.xml).

### taxonID

```{r}
distribution %<>% mutate(taxonID = raw_taxon_id) 
```

### locality

Inspect values:

```{r}
distribution %>% 
  select(raw_locality, raw_country_code) %>% 
  group_by_all() %>% 
  summarize(records = n())
```

Use `case_when` in this case.
When `raw_locality` is empty, use country as a locality:

```{r}
distribution %<>% mutate(locality = case_when(
  is.na(raw_locality) & raw_country_code == "BE" ~ "Belgium",
  is.na(raw_locality) & raw_country_code == "FR" ~ "France",
  is.na(raw_locality) & raw_country_code == "MK" ~ "Macedonia",
  is.na(raw_locality) & raw_country_code == "NL" ~ "The Netherlands",
  TRUE ~ raw_locality))
```

Inspect mapped values: 

```{r}
distribution %>% 
  select(raw_locality, raw_country_code, locality) %>% 
  group_by_all() %>% 
  summarize(records = n())
```

### countryCode

```{r}
distribution %<>% mutate(countryCode = raw_country_code) 
```

### occurrenceStatus

```{r}
distribution %<>% mutate(occurrenceStatus = raw_occurrence_status) 
```

### threatStatus

recode threatStatus:

```{r}
distribution %<>% mutate(threatStatus = recode(raw_threat_status,
  "endangered" = "EN",
  "vulnerable" = "VU"))
```

### source

```{r}
distribution %<>% mutate(source = raw_source) 
```

### occurrenceRemarks

```{r}
distribution %<>% mutate(occurrenceRemarks = raw_remarks) 
```

## Post-processing

Remove the original columns:

```{r}
distribution %<>% select(-starts_with("raw_"))
```

Preview data:

```{r}
distribution %>% head()
```

Save to CSV:

```{r}
write.csv(taxon, file = "../data/processed/taxon.csv", na = "", row.names = FALSE, fileEncoding = "UTF-8")
```




